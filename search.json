[
  {
    "objectID": "paper.html",
    "href": "paper.html",
    "title": "Breaking Free from the Xpt: Exploration of dataset.json as an Alternative Transport File to Regulatory Agencies",
    "section": "",
    "text": "The SAS XPORT (XPT) transport file has been the de facto interchange format for SDTM and ADaM datasets in regulatory submissions for decades. While durable and widely supported, XPT is inherently constrained by legacy design decisions and is not a natural “first choice” format within modern open-source data ecosystems. The CDISC Dataset-JSON standard provides a contemporary alternative designed to represent clinical datasets and metadata using JavaScript Object Notation (JSON), enabling straightforward interaction across many programming languages and validation toolchains.\nR Consortium R Submission Pilot 5 explored a fully reproducible, publicly accessible submission-like package centered on R-generated ADaM datasets and delivery of datasets in Dataset-JSON v1.1. The pilot demonstrates (1) converting study data inputs into analysis-ready datasets, (2) serializing datasets to Dataset-JSON using R, (3) regenerating key tables/figures from the R-derived datasets, and (4) implementing quality control comparisons to support confidence that artifacts match expectations and prior baselines.\nThis paper summarizes the background and motivations for Dataset-JSON, the R Consortium Working Group context, and the Pilot 5 implementation and lessons learned for teams evaluating Dataset-JSON as a viable alternative transport format for future submissions."
  },
  {
    "objectID": "paper.html#abstract",
    "href": "paper.html#abstract",
    "title": "Breaking Free from the Xpt: Exploration of dataset.json as an Alternative Transport File to Regulatory Agencies",
    "section": "",
    "text": "The SAS XPORT (XPT) transport file has been the de facto interchange format for SDTM and ADaM datasets in regulatory submissions for decades. While durable and widely supported, XPT is inherently constrained by legacy design decisions and is not a natural “first choice” format within modern open-source data ecosystems. The CDISC Dataset-JSON standard provides a contemporary alternative designed to represent clinical datasets and metadata using JavaScript Object Notation (JSON), enabling straightforward interaction across many programming languages and validation toolchains.\nR Consortium R Submission Pilot 5 explored a fully reproducible, publicly accessible submission-like package centered on R-generated ADaM datasets and delivery of datasets in Dataset-JSON v1.1. The pilot demonstrates (1) converting study data inputs into analysis-ready datasets, (2) serializing datasets to Dataset-JSON using R, (3) regenerating key tables/figures from the R-derived datasets, and (4) implementing quality control comparisons to support confidence that artifacts match expectations and prior baselines.\nThis paper summarizes the background and motivations for Dataset-JSON, the R Consortium Working Group context, and the Pilot 5 implementation and lessons learned for teams evaluating Dataset-JSON as a viable alternative transport format for future submissions."
  },
  {
    "objectID": "paper.html#introduction",
    "href": "paper.html#introduction",
    "title": "Breaking Free from the Xpt: Exploration of dataset.json as an Alternative Transport File to Regulatory Agencies",
    "section": "INTRODUCTION",
    "text": "INTRODUCTION\n\nWhat we are going to talk about\nThis paper covers four related topics:\n\nWhy the industry is reevaluating long-standing dataset transport assumptions (with XPT as the historical default).\nWhat is Dataset-JSON, where it came from, and why it matters.\nThe R Consortium R Submissions Working Group context that enabled Pilot 5.\nR Submission Pilot 5, with emphasis on the Dataset-JSON implementation, reproducible workflows, and what we learned.\n\n\n\nA high-level framing: why XPT feels like yesterday’s solution\nXPT is not “bad”— as it is widely supported and deeply embedded in regulatory processes. However, when viewed through a modern software lens, it unduly burdens the acceptance of modern software practices and adoption of new data standards. In this section, we will lay out why the xpt is problematic.\nOutdated Technology: The format was defined in the 1980s and was designed for data transfer between SAS applications on different operating systems. It is not aligned with modern data architectures or standards like Fast Healthcare Interoperability Resources (FHIR) or big-data. The FDA adopted it as non-proprietary data format to submit for drug submissions.\nLimited Data Characteristics: Variable Names are restricted to a maximum of 8 characters and are case-insensitive. Variable Labels are limited to 40 characters. Character Variable Lengths cannot exceed 200 characters or bytes. Variable Types are limited to US ASCII for character variables and IBM INTEGER and DOUBLE for numeric variables.\nPoor Handling of International Characters: It only supports US ASCII character encoding, meaning it cannot natively handle multibyte characters or UTF-8. Representing international characters requires “tricks” or workarounds, which can lead to encoding and interpretation issues.\nLack of Robust Metadata: The .xpt format has no direct way to embed rich metadata within the file itself. It relies on separate define.xml files, which introduces the risk of data and metadata mismatches if not carefully managed.\nInefficient Storage: The format is inefficient, often leading to wasted storage space. It allocates fixed space for variables, and missing or shorter values are padded with blanks, which can result in up to 70% wasted space. It also does not support data compression.\nEcosystem asymmetry: XPT is universally known in SAS-centric workflows, but is less native to open-source tooling and data engineering stacks.\nThis is the motivation for exploring Dataset-JSON: not to declare a villain, but to ask whether an alternative transport can reduce friction and better fit modern, reproducible, open toolchains while continuing to support reviewer needs."
  },
  {
    "objectID": "paper.html#datasetjson",
    "href": "paper.html#datasetjson",
    "title": "Breaking Free from the Xpt: Exploration of dataset.json as an Alternative Transport File to Regulatory Agencies",
    "section": "datasetjson",
    "text": "datasetjson\n\nA brief “history lesson”\nIn 2022, the FDA evaluated alternatives to serve as possible replacements to SAS V5 XPT. The FDA determined that JSON was the optimal modern format to serve as a replacement to SAS V5 XPT. CDISC Datsaet-JSON v1.0 was released in Aug 2023 and the datasetjson R package supporting this version was released in Oct 2023. Dataset-JSON is a CDISC standard intended to represent clinical tabular datasets using JSON. It exists in the context of increasing adoption of structured data standards and the need to support interoperability beyond a single vendor ecosystem. It is designed to meet a wide range of data exchange scenarios including regulatory submissions and API-based data sharing.\n\n\nWhat Dataset-JSON is (practically)\nDataset-JSON can be thought of as a standard way to serialize a dataset plus its metadata into JSON. In practical terms it enables:\n\ntransport of rows/records in JSON form\nrepresentation of column metadata (name, label, type, etc.)\nconsistent schema that can be validated\ncontains one dataset per file\neach dataset can optionally reference a Define-XML file\n\nThe standard addresses requirements from the PHUSE 2017 “Transport for the Next Generation” paper. It follows a lowerCamelCase structure with three main components: top-level metadata (including creation datetime, version, and optional Define-XML references), column metadata (specifying variable names, labels, and data types), and row data arrays. It supports multiple data types with special handling for decimal precision (exchanged as strings to avoid rounding) and ISO 8601 format for date/time variables, with missing values represented as null. The standard also offers an NDJSON format (.ndjson) that enables streaming of large datasets by placing metadata on the first line and individual data rows on subsequent lines, allowing processing without loading entire datasets into memory.\n\n\nRegulatory context and momentum\nIn April 2025, the FDA published a Federal Register notice reinforcing CDISC standards for electronic study data submission, signaling regulatory openness to transport format evolution. This context makes Dataset-JSON increasingly relevant as the industry evaluates alternatives to legacy transport mechanisms while maintaining compliance with CDISC standards.\n\n\nCollaboration framing (CDISC / PHUSE / FDA / R Consortium)\nIndustry adoption of submission changes typically succeeds only where standards bodies, industry groups, and regulators align around feasibility and reviewer usability. Dataset-JSON exists within this collaborative ecosystem where CDISC defines standards, PHUSE supports applied use cases and community practice, and FDA engagement is critical to evaluate submission and review implications.\nWhile this paper is not a policy paper, Pilot 5 is explicitly framed as an FDA–industry collaboration through the R Consortium and serves as a public “show your work” style example."
  },
  {
    "objectID": "paper.html#why-dataset-json-over-other-modern-formats",
    "href": "paper.html#why-dataset-json-over-other-modern-formats",
    "title": "Breaking Free from the Xpt: Exploration of dataset.json as an Alternative Transport File to Regulatory Agencies",
    "section": "WHY DATASET-JSON OVER OTHER MODERN FORMATS",
    "text": "WHY DATASET-JSON OVER OTHER MODERN FORMATS\nWhile modern formats like Parquet offer performance advantages for big data applications, Dataset-JSON provides specific benefits for regulatory submissions:\n\nSelf-contained metadata: Variable labels, types, and CDISC-specific metadata are embedded directly in the file, eliminating external dependencies.\nHuman-readable and audit-friendly: Text-based JSON enables review, comparison, and validation using standard development tools without specialized software.\nUniversal parsing: JSON parsers exist in virtually every programming language, reducing implementation barriers across toolchains.\nAPI-Based Exchange Dataset-JSON supports both API and file based exchange\n\nBinary formats sacrifice these readability and auditability characteristics—considerations that matter critically in regulatory review contexts where transparency and reproducibility are paramount."
  },
  {
    "objectID": "paper.html#r-consortium-working-group",
    "href": "paper.html#r-consortium-working-group",
    "title": "Breaking Free from the Xpt: Exploration of dataset.json as an Alternative Transport File to Regulatory Agencies",
    "section": "R CONSORTIUM WORKING GROUP",
    "text": "R CONSORTIUM WORKING GROUP\n\nWhat is the focus?\nThe R Consortium R Submissions Working Group has focused on demonstrating that open-source, R-based submission packages can be organized, reproduced, and reviewed in a way that meets regulatory expectations. A key theme across pilots is transparency: making the full submission-like artifact available (data, code, documentation, and outputs), enabling learning and reuse across industry. The mission is:\n\nEasier R-based clinical trial regulatory submissions today\n\nby showing open examples of using current submission portals\n\nEasier R-based clinical trial regulatory submissions tomorrow\n\nby collecting feedback and influencing future industry and agency decisions on system/process setup\n\n\nEach Pilot’s goals as well supporting documentation can be found on the R Consortium’s Submissions Working Group website. The link can be found below.\n\n\nSuccesses (as demonstrated by the pilots)\nAcross the pilot work, the working group has demonstrated:\n\nsubmission-like packaging conventions (eCTD-style organization),\nreproducible execution from raw/source materials through outputs,\npublic documentation (e.g., ADRG) aligning to reviewer needs,\npractical workflows that teams can fork and adapt.\n\nEach Pilot has worked extensively with FDA reviewers to discuss issues from installation of packages, data issues, derivation in R and more. Once the Pilot is completed, the FDA provides recognition of the successful review with a “Statistical Review and Evaluation” letter. Pilot 3’s letter is linked in the Reference materials.\n\n\nProblems identified and iterations\nExploring new transport mechanisms and reproducible workflows surfaces practical issues that do not always appear in “standards only” discussions, including:\n\nensuring variable labels, formats, and metadata persist predictably across conversions,\nmanaging numeric precision and representation choices,\naligning generated deliverables with reviewer expectations and available tooling,\nmaintaining robust QC evidence when changing transport mechanisms.\n\nPilot 5 contains concrete code and QC artifacts illustrating how these issues can be surfaced, addressed, and documented in a public workflow. Pilot 5 uses Dataset-JSON v1.1 and demonstrates converting and producing these artifacts using R in a transparent manner."
  },
  {
    "objectID": "paper.html#pilot-5",
    "href": "paper.html#pilot-5",
    "title": "Breaking Free from the Xpt: Exploration of dataset.json as an Alternative Transport File to Regulatory Agencies",
    "section": "PILOT 5",
    "text": "PILOT 5\n\nFocus of Pilot 5 (Dataset-JSON + R-generated ADaM)\nPilot 5 objectives include delivering a publicly accessible R-based submission package using Dataset-JSON, and expanding prior pilot approaches by generating ADaM datasets using R. For a little bit of history, Pilot 1 created 3 tables and 1 figure all in R, which was submitted to the FDA back in 2021. The SDTM and ADaM datasets used in Pilot 1 were produced in SAS as xpt files. Pilot 3 built on these 3 tables and 1 figure by now rebuilding the ADaM datasets in R and outputting as xpt files. However, there were only 5 datasets needed for the needs of the 3 tables and 1 figure - so only 5 were made in R. Remember the Pilots are more about investigating how the process works and less on the content created in R - hence the small package to help stay focused.\nNow enter Pilot 5. Building off the success of Pilot 1 and Pilot 3 we wanted to see if all the xpt files in the submission package could be converted to datasetjson. The amazing datasetjson R package is available to help do a lot of the heavy lifting. See below for more information on it. As most of the code was in place for the tables, figures and ADaMs, we only had to add minimal code to produce the xpts into datasetjson.\nThe datasetjson R package also had a handy conversion program for moving existing xpts to datasetjson. The Pilots do not have access to the raw data and so the SDTM could not be re-created from scratch. Please see the below links to see Pilot 5 artifacts.\nPrimary public entry points include:\n\nRepo overview: https://github.com/RConsortium/submissions-pilot5-datasetjson\neCTD-like package README (Quarto): https://github.com/RConsortium/submissions-pilot5-datasetjson/blob/main/ectd_readme/README.qmd\n\nADRG previews referenced by the repo README:\n\nHTML: https://rpodcast.quarto.pub/pilot-5-aanalysis-data-reviewers-guide/\nPDF: https://rsubmission-draft.us-east-1.linodeobjects.com/pilot5-adrg-quarto-pdf.pdf\n\n\n\n\nWay of working: reproducibility-first\nPilot 5 is organized to be rerunnable and inspectable, including:\n\ndataset generation programs under pilot5-submission/pilot5-programs/ (e.g., adsl.r, adae.r, adlbc.r, adtte.r),\noutputs and derived artifacts under pilot5-submission/pilot5-output/,\ndocumentation such as ADRG and eCTD README.\n\nMost importantly, Pilot 5 treats comparability as an artifact. For example:\n\nqcReport.qmd compares Pilot 5 ADaM datasets against prior baseline artifacts using diffdf.\ntlf-qc.qmd supports comparing generated output artifacts, including text diffs and image-style comparisons.\n\n\n\nAI infrastructure (where it helped)\nPilot 5 includes experimental automation to assist documentation workflows, including LLM-assisted pipelines for extracting information (e.g., variables, datasets, and filters) from analysis code to support reviewer documentation tables (see adrg/llm-adrg-utils/llm_pipeline.qmd). This is not positioned as a replacement for authoring, but as a mechanism to reduce manual effort and improve consistency when building reviewer-facing documentation from code.\n\n\nSuccess of the Pilot (what Pilot 5 demonstrates)\nPilot 5 demonstrates, with a public reference implementation, that:\n\nDataset-JSON can be produced in an R-driven pipeline with explicit metadata management.\nA submission-like artifact can be packaged in a reviewer-friendly structure.\nOutputs can be regenerated from the provided code and datasets.\nQC comparisons can be scripted and reported to support confidence in the fidelity of the produced artifacts.\n\n\n\nTrials and tribulations (what you run into in the real world)\nPilot 5 encountered a couple of challenges along the way in bringing our submission package to the FDA grouped into standards and technical hurdle.\nFor standards, the first issue was that the standard of datasetjson had just switched from 1.0 to 1.1 so we needed to understand the differences for discussion with FDA. Second, we make use of the Validation software Pinnacle 21 Community v4.1.0 (the latest available at the time of writing), which helps ensure compliance for submissions packages. Unfortunately, the standard 1.1 was not available in either the community or enterprise version of the software. A bit of setback, but we worked with our FDA partners to address and have documented this in the FDA submission. Once the standard 1.1 is available in the Pinnacle 21 we might re-submit.\nFor technical, the first issue was learning how the metadata is applied and stored in the datasetjson format as we have to ensure consistency. The second issue was learning about converting float variables to decimal data type in the JSON output. This was a bit of a thorn in our side in the initial development. Eventually, a wrapper function was built to help provide consistency across all the datasets. There are also a few limitations to the R package datasetjson which are being looked into by the team."
  },
  {
    "objectID": "paper.html#mini-example-from-an-adam-data-frame-to-dataset-json",
    "href": "paper.html#mini-example-from-an-adam-data-frame-to-dataset-json",
    "title": "Breaking Free from the Xpt: Exploration of dataset.json as an Alternative Transport File to Regulatory Agencies",
    "section": "MINI EXAMPLE: FROM AN ADAM DATA FRAME TO DATASET-JSON",
    "text": "MINI EXAMPLE: FROM AN ADAM DATA FRAME TO DATASET-JSON\nThis section provides a minimal illustration of how Dataset-JSON can be produced in R in the same spirit as the Pilot 5 workflow. The goal is to show that Dataset-JSON creation is a reproducible, scriptable step that can be version-controlled and QC’d like any other artifact.\nPilot 5 conversion logic is exemplified by scripts such as pilot5-submission/pilot5-programs/convert_xpt_to_datasetjson.r (read source data, ensure labels, derive column metadata, write Dataset-JSON).\nBelow is a simplified “toy” example mirroring that concept.\n\nlibrary(datasetjson)\nlibrary(tibble)\n\nadsl &lt;- tibble(\n  STUDYID = \"CDISCPILOT01\",\n  USUBJID = c(\"01-701-1015\", \"01-701-1023\"),\n  TRT01A  = c(\"Placebo\", \"Xanomeline Low Dose\"),\n  AGE     = c(67, 72)\n)\n\n# Dataset label (Pilot 5 ensures labels exist; may be derived from source metadata)\nattr(adsl, \"label\") &lt;- \"Subject-Level Analysis Dataset\"\n\n# Minimal column metadata (Pilot 5 derives more comprehensive metadata)\ncolumns &lt;- tibble::tibble(\n  itemOID = names(adsl),\n  name = names(adsl),\n  label = c(\"Study Identifier\", \"Unique Subject Identifier\", \"Actual Treatment for Period 01\", \"Age\"),\n  dataType = c(\"string\", \"string\", \"string\", \"integer\")\n)\n\nds_json &lt;- datasetjson::dataset_json(\n  adsl,\n  item_oid = \"ADSL\",\n  name = \"adsl\",\n  dataset_label = attr(adsl, \"label\"),\n  columns = columns\n)\n\njson_text &lt;- datasetjson::write_dataset_json(ds_json, pretty = TRUE)\n# writeLines(json_text, \"adsl.json\")\ncat(json_text)\n\n{\n  \"datasetJSONCreationDateTime\": \"2026-02-02T18:44:47\",\n  \"datasetJSONVersion\": \"1.1.0\",\n  \"itemGroupOID\": \"ADSL\",\n  \"records\": 2,\n  \"name\": \"adsl\",\n  \"label\": \"Subject-Level Analysis Dataset\",\n  \"columns\": [\n    {\n      \"itemOID\": \"STUDYID\",\n      \"name\": \"STUDYID\",\n      \"label\": \"Study Identifier\",\n      \"dataType\": \"string\"\n    },\n    {\n      \"itemOID\": \"USUBJID\",\n      \"name\": \"USUBJID\",\n      \"label\": \"Unique Subject Identifier\",\n      \"dataType\": \"string\"\n    },\n    {\n      \"itemOID\": \"TRT01A\",\n      \"name\": \"TRT01A\",\n      \"label\": \"Actual Treatment for Period 01\",\n      \"dataType\": \"string\"\n    },\n    {\n      \"itemOID\": \"AGE\",\n      \"name\": \"AGE\",\n      \"label\": \"Age\",\n      \"dataType\": \"integer\"\n    }\n  ],\n  \"rows\": [\n    [\n      \"CDISCPILOT01\",\n      \"01-701-1015\",\n      \"Placebo\",\n      67.0\n    ],\n    [\n      \"CDISCPILOT01\",\n      \"01-701-1023\",\n      \"Xanomeline Low Dose\",\n      72.0\n    ]\n  ]\n}\n\n\nEven in this simplified example, Dataset-JSON highlights two operational advantages that Pilot 5 leverages: - metadata is handled explicitly and can be audited, - the resulting artifact is plain text JSON and fits naturally into diffs, reviews, and automated checks."
  },
  {
    "objectID": "paper.html#conclusion",
    "href": "paper.html#conclusion",
    "title": "Breaking Free from the Xpt: Exploration of dataset.json as an Alternative Transport File to Regulatory Agencies",
    "section": "CONCLUSION",
    "text": "CONCLUSION\nR Consortium R Submission Pilot 5 provides a concrete, public example demonstrating that Dataset-JSON can be used as a realistic alternative transport format in a submission-like package while maintaining reproducibility and reviewability. The pilot shows that Dataset-JSON can support the same scientific intent and reproducibility expectations traditionally associated with XPT-based submissions. This is achieved by pairing Dataset-JSON with transparent dataset derivation code, explicit metadata management, and reviewer-oriented packaging and documentation (eCTD-like structure + ADRG). First-class QC reporting (dataset and output comparisons) further strengthens confidence in the approach. Together, these elements align more naturally with modern open-source data workflows while maintaining regulatory standards."
  },
  {
    "objectID": "paper.html#references",
    "href": "paper.html#references",
    "title": "Breaking Free from the Xpt: Exploration of dataset.json as an Alternative Transport File to Regulatory Agencies",
    "section": "REFERENCES",
    "text": "REFERENCES\nStatistical Review and Evaluation. (2024). GitHub. https://github.com/RConsortium/submissions-wg/blob/main/_Documents/Summary_R_Pilot3_Submission.pdf\nR Consortium R Submission Pilot 5 development repository. (2025). GitHub.\nhttps://github.com/RConsortium/submissions-pilot5-datasetjson\nR Consortium Pilot 5 eCTD package overview. (2025). GitHub (Quarto source).\nhttps://github.com/RConsortium/submissions-pilot5-datasetjson/blob/main/ectd_readme/README.qmd\nFDA Electronic Common Technical Document (eCTD) overview. (n.d.). U.S. Food and Drug Administration.\nhttps://www.fda.gov/drugs/electronic-regulatory-submission-and-review/electronic-common-technical-document-ectd\nCDISC SDTM & ADaM Pilot Project (CDISCPilot01 source materials). (n.d.). GitHub.\nhttps://github.com/cdisc-org/sdtm-adam-pilot-project\nElectronic Study Data Submission; Data Standards; Clinical Data Interchange Standards Consortium Dataset-JavaScript Object Notation; Request for Comments. Federal Register. (2025, April 9). https://www.federalregister.gov/documents/2025/04/09/2025-06051/electronic-study-data-submission-data-standards-clinical-data-interchange-standards-consortium\nGithub. (2025). Github Copilot (GPT-4.1, 14 April version) [Large Language Model]. https://github.com/copilot/\nOpenAI. (2025). GPT-4.1 (14 April version) [Large language model]. https://platform.openai.com\nOpenAI. (2025). GPT-5.1 (12 November version) [Large language model]. https://platform.openai.com"
  },
  {
    "objectID": "paper.html#recommended-reading",
    "href": "paper.html#recommended-reading",
    "title": "Breaking Free from the Xpt: Exploration of dataset.json as an Alternative Transport File to Regulatory Agencies",
    "section": "RECOMMENDED READING",
    "text": "RECOMMENDED READING\nPilot 5 ADRG preview (public links referenced by the Pilot 5 repo README):\n\nHTML: https://rpodcast.quarto.pub/pilot-5-aanalysis-data-reviewers-guide/\n\nPDF: https://rsubmission-draft.us-east-1.linodeobjects.com/pilot5-adrg-quarto-pdf.pdf\n\nQC reports in the Pilot 5 repo:\n\nqcReport.qmd\ntlf-qc.qmd\n\nLLM-assisted ADRG utilities (Pilot 5 repo):\n\nadrg/llm-adrg-utils/llm_pipeline.qmd"
  },
  {
    "objectID": "paper.html#acknowledgments",
    "href": "paper.html#acknowledgments",
    "title": "Breaking Free from the Xpt: Exploration of dataset.json as an Alternative Transport File to Regulatory Agencies",
    "section": "ACKNOWLEDGMENTS",
    "text": "ACKNOWLEDGMENTS\nThe authors acknowledge the work of the R Consortium and the R Submissions Working Group, as well as the broader set of contributors who made the Pilot 5 repository, documentation, and reproducible workflows publicly available for the benefit of regulators, industry, and the open-source community."
  },
  {
    "objectID": "paper.html#contact-information",
    "href": "paper.html#contact-information",
    "title": "Breaking Free from the Xpt: Exploration of dataset.json as an Alternative Transport File to Regulatory Agencies",
    "section": "CONTACT INFORMATION",
    "text": "CONTACT INFORMATION\nBen Straub\nGSK\nPhiladelphia, United States\nSam Parmar\nPfizer\nNew York City, United States\nNick Masel\nJohnson and Johnson\nRaleigh, United States\nBrand and product names are trademarks of their respective companies."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Breaking Free from the Xpt",
    "section": "",
    "text": "This is a Quarto site for the PHUSE US Connect 2026 talk titled “Breaking Free from the Xpt: Exploration of dataset.json as an Alternative Transport File to Regulatory Agencies”. It will be presented on Monday, March 26, 2026 in Austin, Texas."
  },
  {
    "objectID": "slides.html#a-time-of-bliss",
    "href": "slides.html#a-time-of-bliss",
    "title": "Breaking Free from the XPT",
    "section": "A time of bliss",
    "text": "A time of bliss"
  },
  {
    "objectID": "slides.html#a-time-of-wonder",
    "href": "slides.html#a-time-of-wonder",
    "title": "Breaking Free from the XPT",
    "section": "A time of wonder",
    "text": "A time of wonder"
  },
  {
    "objectID": "slides.html#a-time-of-memory",
    "href": "slides.html#a-time-of-memory",
    "title": "Breaking Free from the XPT",
    "section": "A time of memory",
    "text": "A time of memory"
  },
  {
    "objectID": "slides.html#a-time-of-xpt",
    "href": "slides.html#a-time-of-xpt",
    "title": "Breaking Free from the XPT",
    "section": "A time of xpt",
    "text": "A time of xpt"
  },
  {
    "objectID": "slides.html#motivation-why-talk-about-transport-formats",
    "href": "slides.html#motivation-why-talk-about-transport-formats",
    "title": "Breaking Free from the XPT",
    "section": "Motivation: Why Talk About Transport Formats?",
    "text": "Motivation: Why Talk About Transport Formats?\n\nAll of these 1980s technologies have been replaced - except the xpt.\nXPTs has been the de facto submission transport for decades\nXPT works – but reflects 1980s constraints, not modern data practice\nOpen-source tooling and modern standards are now mainstream\nDataset-JSON offers a contemporary alternative\n\n\nSet the stage: XPT is familiar and “good enough,” but we’re asking if there’s a better fit for today’s ecosystems, especially for R-based submissions."
  },
  {
    "objectID": "slides.html#agenda",
    "href": "slides.html#agenda",
    "title": "Breaking Free from the XPT",
    "section": "Agenda",
    "text": "Agenda\nThis talk covers three topics:\n\nWhy the industry is rethinking XPT as the default transport file?\nWhat Dataset-JSON is, where it came from, and why it matters?\nThe R Consortium R Submissions Working Group and Pilot 5\n\n\nGive the audience a mental roadmap; we’ll go from pain points, to the new standard, to the pilot as a worked example."
  },
  {
    "objectID": "slides.html#xpt-yesterdays-solution-to-yesterdays-problem",
    "href": "slides.html#xpt-yesterdays-solution-to-yesterdays-problem",
    "title": "Breaking Free from the XPT",
    "section": "XPT: Yesterday’s Solution to Yesterday’s Problem",
    "text": "XPT: Yesterday’s Solution to Yesterday’s Problem\n\nOutdated technology\n\nDefined in the 1980s for SAS-to-SAS transfer\nOptimized for mainframes, not for modern APIs or big data\n\nConstrained data characteristics\n\n8-character variable names, 40-character labels\n200-character limit for character values\nLimited data types\n\nPoor handling of internationalization\n\nUS-ASCII only; no native UTF-8/multibyte support\n\n\n\nEmphasize that XPT isn’t “bad,” but its constraints create friction when we try to adopt modern practices (richer metadata, internationalization, etc.)."
  },
  {
    "objectID": "slides.html#why-xpt-creates-friction-today",
    "href": "slides.html#why-xpt-creates-friction-today",
    "title": "Breaking Free from the XPT",
    "section": "Why XPT Creates Friction Today",
    "text": "Why XPT Creates Friction Today\n\nWeak embedded metadata\n\nNo rich metadata inside the file\nReliance on external Define-XML; risk of misalignment\n\nInefficient storage\n\nFixed-width allocations, lots of padding\nNo compression support\n\nEcosystem asymmetry\n\nNative in SAS; awkward in open-source and data engineering stacks\n\n\n\nConnect these to practical headaches: bloated files, harder QC, more custom glue code in open-source environments."
  },
  {
    "objectID": "slides.html#dataset-json-history",
    "href": "slides.html#dataset-json-history",
    "title": "Breaking Free from the XPT",
    "section": "Dataset-JSON History",
    "text": "Dataset-JSON History\n\nSelected by FDA (2022 evaluation) as an optimal modern format to replace SAS V5 XPT\nFDA April 2025 Federal Register notice:\n\nReaffirms datasetjson standards\nSignals openness to evolving transport mechanisms\n\n\n\n\nDataset-JSON v1.1\n\n\nPosition Dataset-JSON as a CDISC-backed, regulator-aware standard, not just “some JSON flavor.”"
  },
  {
    "objectID": "slides.html#why-dataset-json",
    "href": "slides.html#why-dataset-json",
    "title": "Breaking Free from the XPT",
    "section": "Why Dataset-JSON?",
    "text": "Why Dataset-JSON?\n\nSelf-contained metadata\n\nVariable labels/types and CDISC metadata embedded in the file\nDesigned to meet regulatory needs\n\nHuman-readable and audit-friendly\n\nPlain-text JSON; easy to inspect and search\n\nUniversally parseable\n\nMature JSON parsers exist in all major languages\n\nSupports APIs\n\nSame structure works for file transfer and REST endpoints\n\nInteroperability\n\nThis word is too fancy for me\n\n\n\nContrast with Parquet/other binary formats: great for analytics, less ideal when transparency and audit trails matter for regulators."
  },
  {
    "objectID": "slides.html#dataset-json-in-practice",
    "href": "slides.html#dataset-json-in-practice",
    "title": "Breaking Free from the XPT",
    "section": "Dataset-JSON in Practice",
    "text": "Dataset-JSON in Practice\n\nOne dataset per file\nThree main components:\n\nTop-level metadata\n\nCreation time, standard version\nOptional link to Define-XML\n\nColumn metadata\n\nNames, labels, data types, optional CDISC-specific attributes\n\nRow data\n\nArrays of values; missing values as null\n\n\nSpecial handling:\n\nDecimals as strings to preserve precision\nISO 8601 dates/times\nOptional NDJSON variant for streaming large datasets\n\n\n\nHighlight that Dataset-JSON encodes both data and metadata in one place, which is a key difference from XPT + separate Define-XML."
  },
  {
    "objectID": "slides.html#regulatory-and-collaboration-context",
    "href": "slides.html#regulatory-and-collaboration-context",
    "title": "Breaking Free from the XPT",
    "section": "Regulatory and Collaboration Context",
    "text": "Regulatory and Collaboration Context\n\nDataset-JSON sits in a collaborative ecosystem:\n\nCDISC: defines standards\nPHUSE: applied use cases and community practice\nFDA: evaluates review impact and feasibility\nR Consortium Submission Working Group: FDA–industry collaboration testing out R-based submissions.\n\n\n\nUnderscore that industry change happens when standards bodies, industry, and regulators move together—Pilot 5 contributes evidence."
  },
  {
    "objectID": "slides.html#r-consortium-r-submissions-working-group",
    "href": "slides.html#r-consortium-r-submissions-working-group",
    "title": "Breaking Free from the XPT",
    "section": "R Consortium R Submissions Working Group",
    "text": "R Consortium R Submissions Working Group\n\nMission: demonstrate that R-based submission packages can:\n\nMeet regulatory expectations\nBe fully reproducible and reviewable\nExperiment today to prepare for tomorrow’s submissions\n\nFocus on:\n\nComplete, public submission-like artifacts (data, code, outputs)\nPractical workflows others can fork and adapt\nFeedback loop with regulators to shape future processes\n\n\n\nBriefly mention that multiple pilots exist; we’ll zoom in on Pilot 5 as the Dataset-JSON-focused one."
  },
  {
    "objectID": "slides.html#what-earlier-pilots-showed",
    "href": "slides.html#what-earlier-pilots-showed",
    "title": "Breaking Free from the XPT",
    "section": "What Earlier Pilots Showed",
    "text": "What Earlier Pilots Showed\n\nDemonstrated:\n\neCTD-style packaging and conventions\nReproducible execution from source data through TLFs\nReviewer-aligned documentation (ADRG) using open tools (e.g., Quarto)\nConcrete interaction with FDA reviewers:\n\nInstallation, environment setup\nData and derivation questions\n\nPilots received a letter from FDA called “Statistical Review and Evaluation” which documented success of Pilot as public evidence.\n\n\n\nThis slide builds trust: regulators have already successfully reviewed R-based packages from earlier pilots."
  },
  {
    "objectID": "slides.html#pilots-1---4",
    "href": "slides.html#pilots-1---4",
    "title": "Breaking Free from the XPT",
    "section": "Pilots 1 - 4",
    "text": "Pilots 1 - 4\n\nEvolution:\n\nPilot 1: TLFs in R, SDTM/ADaM from SAS XPT\nPilot 2: TLFs are packaged into a Shiny App\nPilot 3: Rebuilt 5 ADaM datasets in R, still output XPT\nPilot 4: Pilot 2 delivered as webassembly and as a container"
  },
  {
    "objectID": "slides.html#pilot-5-focus-dataset-json-r-generated-adam",
    "href": "slides.html#pilot-5-focus-dataset-json-r-generated-adam",
    "title": "Breaking Free from the XPT",
    "section": "Pilot 5 Focus: Dataset-JSON + R-Generated ADaM",
    "text": "Pilot 5 Focus: Dataset-JSON + R-Generated ADaM\n\n\nObjectives:\n\nConvert all XPTs in the package to Dataset-JSON\nBuild off Pilot 1 and Pilot 3\nDeliver a publicly accessible R-based submission-like package\nUse Dataset-JSON v1.1 as the dataset transport format\nGenerate key ADaM datasets in R (not SAS) and …\nSDTM also regenerated as datasetjson but no program available\nUse the datasetjson R package to do the heavy lifting\n\n\n\nStress that Pilot 5 is both about the format (Dataset-JSON) and demonstrating end‑to‑end R-based dataset generation."
  },
  {
    "objectID": "slides.html#pilot-5-artifacts-what-you-can-see-today",
    "href": "slides.html#pilot-5-artifacts-what-you-can-see-today",
    "title": "Breaking Free from the XPT",
    "section": "Pilot 5 Artifacts (What You Can See Today)",
    "text": "Pilot 5 Artifacts (What You Can See Today)\n\nPublic repository:\n\nhttps://github.com/RConsortium/submissions-pilot5-datasetjson\n\neCTD-like package overview:\n\nectd_readme/README.qmd\n\nADRG available for Pilot 5\nAdditional Contents:\n\nR programs for dataset generation and conversions\nDataset-JSON outputs\nQC reports\nMerged Pulled Requests with CICD checks\n\n\n\nEncourage participants to explore the repo post-session; it’s meant as a starting point they can reuse."
  },
  {
    "objectID": "slides.html#way-of-working-reproducibility-first",
    "href": "slides.html#way-of-working-reproducibility-first",
    "title": "Breaking Free from the XPT",
    "section": "Way of Working: Reproducibility-First",
    "text": "Way of Working: Reproducibility-First\n\nOrganized to be re-runnable and inspectable:\n\nPrograms: pilot5-submission/pilot5-programs/\n\ne.g., adsl.r, adae.r, adlbc.r, adtte.r\n\nOutputs: pilot5-submission/pilot5-output/\nDocumentation: ADRG + eCTD-style README\n\nComparability treated as a first-class artifact:\n\nqcReport.qmd: dataset-to-dataset QC using diffdf\ntlf-qc.qmd: text and graphical diffing of outputs\n\n\n\nKey message: nothing is “magic”; everything is scripted and version-controlled, including conversion to Dataset-JSON and QC."
  },
  {
    "objectID": "slides.html#where-ai-helped-but-didnt-replace-authors",
    "href": "slides.html#where-ai-helped-but-didnt-replace-authors",
    "title": "Breaking Free from the XPT",
    "section": "Where AI Helped (But Didn’t Replace Authors)",
    "text": "Where AI Helped (But Didn’t Replace Authors)\n\nPilot 5 experimented with LLM-assisted documentation:\n\nadrg/llm-adrg-utils/llm_pipeline.qmd\n\nUse cases:\n\nExtract variables, datasets, filters from analysis code\nPre-populate reviewer-facing tables in ADRG\n\nIntent:\n\nReduce manual effort and inconsistencies\nKeep humans firmly in the authoring and review loop\n\n\n\nBrief mention to show forward-looking tooling, but clarify that AI augments, not replaces, human oversight."
  },
  {
    "objectID": "slides.html#challenges-faced",
    "href": "slides.html#challenges-faced",
    "title": "Breaking Free from the XPT",
    "section": "Challenges Faced",
    "text": "Challenges Faced\n\nStandards timing\n\nDataset-JSON moved from v1.0 to v1.1 during pilot\nNeeded to understand and document v1.1 changes with FDA\n\nValidation tooling gap\n\nPinnacle 21 Community v4.1.0 did not yet support Dataset-JSON v1.1\nRequired:\n\nWorkarounds and additional documentation\nDirect discussion with FDA collaborators\n\nPotential re-submission once P21 supports v1.1\n\nLearning how metadata is represented and persisted in Dataset-JSON\nManaging numeric precision:\n\nConverting float variables to decimal data type in JSON\nBuilding wrapper functions for consistent handling across datasets\n\nPackage limitations:\n\ndatasetjson R package has a few open issues\nTracked and discussed publicly:\n\nhttps://github.com/atorus-research/datasetjson/issues\n\n\n\n\nThis illustrates that format innovation can get slightly ahead of validation ecosystems; collaboration and documentation are key."
  },
  {
    "objectID": "slides.html#what-pilot-5-demonstrates",
    "href": "slides.html#what-pilot-5-demonstrates",
    "title": "Breaking Free from the XPT",
    "section": "What Pilot 5 Demonstrates",
    "text": "What Pilot 5 Demonstrates\n\nDataset-JSON is a viable transport for submission-like packages:\n\nProduced fully in an R-driven pipeline\nWith explicit metadata management\n\nA reviewer-friendly, eCTD-style package can use Dataset-JSON instead of XPT\nOutputs (TLFs) can be regenerated from provided code and datasets\nQC comparisons:\n\nDataset-level and output-level\nScripted and reported for transparency\n\n\n\nTie this back to the original motivation: same scientific intent and reproducibility as XPT-based workflows, but better aligned with modern tools."
  },
  {
    "objectID": "slides.html#daatasetjson-r-package-workhorse-of-pilot-5",
    "href": "slides.html#daatasetjson-r-package-workhorse-of-pilot-5",
    "title": "Breaking Free from the XPT",
    "section": "daatasetjson R package (Workhorse of Pilot 5)",
    "text": "daatasetjson R package (Workhorse of Pilot 5)\n\nUsing the datasetjson R package:\n\nStart from an ADaM-like tibble (adsl)\nEnsure dataset label is set (attr(adsl, \"label\"))\nDefine column metadata tibble:\n\nitemOID, name, label, dataType\n\nCall datasetjson::dataset_json():\n\nPass data, dataset name, label, columns metadata\n\nWrite JSON text with write_dataset_json()\n\nOutput:\n\nA plain-text Dataset-JSON file containing:\n\nTop-level metadata\nColumn metadata\nRow data\n\n\n\n\nYou don’t need to show all the code line by line; emphasize that producing Dataset-JSON is a straightforward, scripted transformation."
  },
  {
    "objectID": "slides.html#takeaways-and-next-steps",
    "href": "slides.html#takeaways-and-next-steps",
    "title": "Breaking Free from the XPT",
    "section": "Takeaways and Next Steps",
    "text": "Takeaways and Next Steps\n\nXPT served us well but is misaligned with:\n\nModern open-source ecosystems\nRich metadata and internationalization needs\nText-based, automated, reproducible workflows\n\nDataset-JSON offers:\n\nSelf-contained, human-readable, API-ready transport\nStronger fit with open-source ecosystems\n\nPilot 5:\n\nProvides a public blueprint you can adapt\nInvites further experimentation and feedback with regulators\n\nCall to action:\n\nExplore the Pilot 5 repo\nTry Dataset-JSON in your internal workflows\nEngage via PHUSE / CDISC / R Consortium channels\n\n\n\nEncourage incremental experimentation: start with internal pilots, evaluate tooling, contribute back issues and improvements."
  },
  {
    "objectID": "slides.html#references-contact",
    "href": "slides.html#references-contact",
    "title": "Breaking Free from the XPT",
    "section": "References & Contact",
    "text": "References & Contact\nSelected references\n\nPilot 5 repo: https://github.com/RConsortium/submissions-pilot5-datasetjson\n\neCTD overview: https://www.fda.gov/drugs/electronic-common-technical-document-ectd\nDataset-JSON v1.1: https://cdisc-org.github.io/DataExchange-DatasetJson/doc/dataset-json1-1.html\n\nAuthors\n\nBen Straub, GSK – Philadelphia, United States\n\nSam Parmar, Pfizer – New York City, United States\n\nNick Masel, Johnson & Johnson – Raleigh, United States\n\n\nInvite questions and follow-up discussions; mention that all materials are public and contributions are welcome."
  },
  {
    "objectID": "helpers/paper_feedback.html",
    "href": "helpers/paper_feedback.html",
    "title": "phuse-datasetjson",
    "section": "",
    "text": "Certainly! Below is feedback specifically focused on the clarity of your Introduction section (covering from “## INTRODUCTION” to just before “## datasetjson”), referencing the content and structure as presented."
  },
  {
    "objectID": "helpers/paper_feedback.html#strengths",
    "href": "helpers/paper_feedback.html#strengths",
    "title": "phuse-datasetjson",
    "section": "Strengths",
    "text": "Strengths\n1. Clear Context and Motivation\n- The introduction sets up the problem very clearly. It discusses the long-standing dominance of XPT as a transport format, notes both its durability and its limitations, and highlights how the industry context is changing.\n- The motivation for exploring alternatives is well articulated—the desire for formats that are more compatible with modern, open-source tools and current data standards.\n2. Signposting\n- The explicit list of “What we are going to talk about” provides a helpful roadmap for the paper, letting readers know what to expect in the subsequent sections.\n3. Effective Framing\n- The section “A high-level framing: why XPT feels like yesterday’s solution” sets the scene effectively, summarizing not only what’s old about XPT, but why that matters for today’s workflows.\n- The writing avoids alienating supporters of XPT by clarifying XPT is not “bad,” which positions your argument as thoughtful and measured, rather than adversarial.\n4. Concise, Specific Points\n- The list format (e.g., “Outdated Technology: …”, “Limited Data Characteristics: …”) makes it easy for readers to digest the key limitations of XPT. This breakdown is both organized and accessible. - Each point is supported with concrete details (e.g., variable length restrictions, character encoding issues), which lends credibility and understanding.\n5. Connection to Main Thesis\n- The final sentences in this section (“This is the motivation for exploring Dataset-JSON…”) tie the discussion of XPT’s limitations back to the purpose of your work. This linkage is well-done."
  },
  {
    "objectID": "helpers/paper_feedback.html#suggestions-for-improvement",
    "href": "helpers/paper_feedback.html#suggestions-for-improvement",
    "title": "phuse-datasetjson",
    "section": "Suggestions for Improvement",
    "text": "Suggestions for Improvement\n1. Redundancy/Transitions\n- There is some repetition between the Abstract and these early Introduction paragraphs. For an audience familiar with the context, you may be able to tighten the focus a bit, reducing overlap.\n- Consider adding very brief transitions between sections—e.g., a linking sentence between the list of what you’ll cover and the start of the XPT critique, to reinforce flow.\n2. Level of Detail\n- Your bullet points (on XPT limitations) are clear, but some could be condensed further, or combined, if brevity is prized.\n- The “Ecosystem asymmetry” and “Automation friction” bullets could be a bit more concrete: consider a short example, or a sentence explaining how text-based formats like JSON facilitate automation.\n3. Balance of Tone\n- The phrase “to ask whether an alternative transport can reduce friction and better fit modern, reproducible, open toolchains while continuing to support reviewer needs” is clear, but would be even stronger if you directly foreshadow that your paper will present concrete evidence or a case study supporting this, to further motivate the reader.\n4. Roadmap Placement\n- The list “This paper covers four related topics:” is located after several paragraphs of introductory text. Some readers may expect a high-level outline a bit earlier; consider moving this up sooner (perhaps just before the “why XPT feels like yesterday’s solution” subsection).\n5. Minor Typos/Clarity - “xpt” should be consistently capitalized as “XPT”. - A few sentences are a bit long or conversational, for instance: “In this section, we will lay out why the xpt is problematic.” For a publication, it can be tightened to: “This section outlines XPT’s limitations.”\n- One typo: “rember” should be “remember”."
  },
  {
    "objectID": "helpers/paper_feedback.html#overall-impression",
    "href": "helpers/paper_feedback.html#overall-impression",
    "title": "phuse-datasetjson",
    "section": "Overall Impression",
    "text": "Overall Impression\n\nThe introduction is clear, well organized, and sets up the paper’s purpose effectively.\n\nIt contextualizes both the technical and regulatory/compliance issues and succinctly motivates the need for an alternative.\nThe use of signposting and bullet points improves readability.\nJust a little tightening and more active transitions would make it even better.\n\n\nSummary Table\n\n\n\n\n\n\n\n\nAspect\nClarity\nSuggested Action\n\n\n\n\nMotivation\nVery clear\n-\n\n\nProblem definition\nConcrete, well described\n-\n\n\nOrganization\nStrong bullet points\nMove roadmap up earlier\n\n\nTone/Balance\nObjective, professional\nEnsure consistent capitalization/terms\n\n\nTransitions\nAdequate\nAdd linking sentences for flow\n\n\nLevel of detail\nAppropriate\nSlight tightening of overlap\n\n\n\n\nIf you revise with these suggestions in mind (especially with transitions, placement of the roadmap, and tightening up small areas of repetition or wordiness), your introduction will be very strong for a Phuse or similar technical audience. Let me know if you have follow-up questions or want feedback on another specific section!"
  },
  {
    "objectID": "slides_long.html",
    "href": "slides_long.html",
    "title": "Breaking Free from the XPT",
    "section": "",
    "text": "title: “Breaking Free from the Xpt” subtitle: “Exploration of dataset.json as an Alternative Transport File to Regulatory Agencies” author: - “Ben Straub (GSK)” - “Sam Parmar (Pfizer)” - “Nick Masel (Johnson & Johnson)” format: revealjs: theme: simple incremental: true slide-number: true transition: fade"
  },
  {
    "objectID": "slides_long.html#dataset-json-as-an-alternative-transport-format",
    "href": "slides_long.html#dataset-json-as-an-alternative-transport-format",
    "title": "Breaking Free from the XPT",
    "section": "Dataset-JSON as an Alternative Transport Format",
    "text": "Dataset-JSON as an Alternative Transport Format\n\nFrom SAS XPT to Dataset-JSON\nR Consortium R Submissions Working Group\nPilot 5: R-generated ADaM + Dataset-JSON\nLessons, challenges, and how you can start\n\n\nFrame the talk as a journey: not “SAS vs R” or “XPT vs JSON” but reducing friction and enabling modern, open, reproducible workflows while still meeting regulatory needs."
  }
]